{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Product Review Scraper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from urllib import parse\n",
    "from numpy import random\n",
    "from time import sleep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request URL Setup\n",
    "\n",
    "The url links to the first (or subsequent) verified purchase customer review page of an Amazon product. The review data is to be used to find insights on the flavour preferences of consumers of a particular product so the product is expected to be offered in different flavours i.e. each review has a \"Flavour Name\" descriptor.\n",
    "\n",
    "A common user agent is passed to the requests module .get method to mitigate the risk of being restricted from access by Amazon. This user agent argument to the headers parameter allows the program to imitate a request from a regular web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready input to request\n",
    "url = \"https://www.amazon.ca/Pure-Protein-Chocolate-Deluxe-6-Count/product-reviews/B00BMHB51I/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&pageNumber=1\"\n",
    "\n",
    "HEADERS = ({'User-Agent':\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "            'Accept-Language': 'en-US, en;q=0.5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    \"\"\"sends request to url and returns a soup object representing the html at that url\"\"\"\n",
    "    response = requests.get(url,headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Scraping\n",
    "\n",
    "For each review, a dictionary is created that stores its ID, title, content, flavour purchased and a boolean stating whether the review was from a foreign country.\n",
    "\n",
    "Output: reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape reviews\n",
    "rev_dicts = []\n",
    "while url:\n",
    "    try:\n",
    "        # random wait time between requests\n",
    "        t = random.uniform(0,0.5)\n",
    "        sleep(t)\n",
    "        soup = get_page(url)\n",
    "        reviews = soup.find_all(name=\"div\",attrs={\"class\":\"a-section celwidget\"})\n",
    "        if reviews is None:\n",
    "            print(\"Error: no reviews found\")\n",
    "            print(url)\n",
    "            break\n",
    "\n",
    "        for item in reviews:\n",
    "            rev_dict = {}\n",
    "\n",
    "            # get review id\n",
    "            m = re.search(r\"^customer_review(_foreign)?-(.+)$\",item['id'])\n",
    "            if m:\n",
    "                rev_id = m.group(2)\n",
    "                rev_dict['id'] = rev_id\n",
    "\n",
    "                # mark if review was foreign\n",
    "                if m.group(1):\n",
    "                    rev_dict['foreign']=True\n",
    "                else:\n",
    "                    rev_dict['foreign']=False\n",
    "            else:\n",
    "                print(\"Error: ID not found in customer review\")\n",
    "                print(item)\n",
    "                break\n",
    "\n",
    "            # get review title\n",
    "            if not rev_dict['foreign']:\n",
    "                rev_title = item.find(\"a\",attrs={\"data-hook\":\"review-title\"}).get_text().strip()\n",
    "                rev_dict['title'] = rev_title\n",
    "            else:\n",
    "                rev_title = item.find(\"span\",attrs={\"data-hook\":\"review-title\"}).get_text().strip()\n",
    "                rev_dict['title'] = rev_title\n",
    "\n",
    "            # get flavour name\n",
    "            info_strip= item.find(\"a\",attrs={\"data-hook\":\"format-strip\"}).get_text(separator=\",\",strip=True)\n",
    "            m = re.search(r\"Flavour Name: (.+?)(,|$)\",info_strip)\n",
    "            if m:\n",
    "                rev_flavour = m.group(1)\n",
    "                rev_dict['flavour'] = rev_flavour\n",
    "            else:\n",
    "                rev_dict['flavour'] = 'NA'\n",
    "            \n",
    "            # get review content\n",
    "            content = item.find(\"div\",attrs={\"class\":\"a-row a-spacing-small review-data\"})\n",
    "            for br in content.find_all(\"br\"):\n",
    "                br.replace_with(\"\\n\")\n",
    "            \n",
    "            rev_dict['content'] = content.get_text()\n",
    "            rev_dicts.append(rev_dict)\n",
    "\n",
    "        # go to next page\n",
    "        next_div = soup.find(\"div\",attrs={\"class\":\"a-form-actions a-spacing-top-extra-large\"})\n",
    "        li = next_div.find(\"li\",attrs={\"class\":\"a-last\"})\n",
    "        a_tag = li.find(\"a\")\n",
    "        if a_tag:\n",
    "            rel_url = a_tag.get(\"href\")\n",
    "            url = parse.urljoin(url,rel_url)\n",
    "        else:\n",
    "            url = None\n",
    "    # catching url where error occurs\n",
    "    except Exception as e:\n",
    "        print(url)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2089\n"
     ]
    }
   ],
   "source": [
    "# confirm reviews scraped\n",
    "print(len(rev_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "with open(\"reviews.json\",\"w\") as f:\n",
    "    json.dump(rev_dicts,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amzscraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2c85490e556883314cc3025ee24e4f17874aa3f48e7b3e45849e810542dae2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
